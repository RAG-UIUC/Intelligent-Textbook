{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fcce97f",
   "metadata": {},
   "source": [
    "# Chapter 1: What Are AI Agents?\n",
    "\n",
    "## Welcome to Agentic Engineering! ğŸš€\n",
    "\n",
    "In this chapter, we'll explore the fundamental concepts of AI agentsâ€”autonomous systems that perceive their environment, make decisions, and take actions to achieve goals. By the end, you'll understand how agents work and build your first interactive agent.\n",
    "\n",
    "> **Key Question**: What makes something an \"agent\" rather than just a program?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909cb3a4",
   "metadata": {},
   "source": [
    "### Context\n",
    "\n",
    "This notebook is the **deep dive companion** to the [Chapter 1 Overview](Chapter_1_Overview.md). If you haven't read the overview yet, start there first to understand the big picture. Then come here to:\n",
    "\n",
    "- ğŸ® **Experiment** with interactive widgets\n",
    "- ğŸ’» **Run code** and modify it\n",
    "- ğŸ“Š **Visualize** agent behavior in real-time\n",
    "- ğŸ¯ **Complete challenges** to test your understanding\n",
    "\n",
    "### How to Use This Notebook\n",
    "\n",
    "Each section includes:\n",
    "1. **Explanation**: What this concept means\n",
    "2. **Code Example**: Implementation you can run\n",
    "3. **Interactive Widget**: Experiment with parameters\n",
    "4. **Visualization**: See results in real-time\n",
    "\n",
    "**Pro Tips:**\n",
    "- âœ‹ Click cells and modify the code - see what happens!\n",
    "- ğŸ”„ Re-run cells with different inputs\n",
    "- ğŸ“ Add your own cells to experiment\n",
    "- ğŸ’¾ Save your work locally if you want to keep changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6032a30e",
   "metadata": {},
   "source": [
    "## 1. What Are AI Agents?\n",
    "\n",
    "### Definition\n",
    "An **AI agent** is an autonomous entity that:\n",
    "- **Perceives** its environment through sensors\n",
    "- **Reasons** about what to do based on goals and knowledge\n",
    "- **Acts** to change its environment through actuators\n",
    "- **Learns** and adapts from experience\n",
    "\n",
    "### The Agent Loop\n",
    "\n",
    "Every agent follows a continuous cycle:\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚        AGENT FEEDBACK LOOP              â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  1. PERCEIVE: Gather environmental data â”‚\n",
    "â”‚        â†“                                  â”‚\n",
    "â”‚  2. REASON: Process & decide             â”‚\n",
    "â”‚        â†“                                  â”‚\n",
    "â”‚  3. ACT: Execute actions                 â”‚\n",
    "â”‚        â†“                                  â”‚\n",
    "â”‚  4. LEARN: Update knowledge              â”‚\n",
    "â”‚        â†“ (cycle repeats)                 â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### What Makes an Agent Different?\n",
    "\n",
    "| Aspect | Traditional Program | AI Agent |\n",
    "|--------|-------------------|----------|\n",
    "| **Input** | Structured data | Sensors (camera, text, data) |\n",
    "| **Processing** | Fixed algorithms | Adaptive reasoning |\n",
    "| **Output** | Predetermined responses | Goal-oriented decisions |\n",
    "| **Adaptation** | Static | Dynamic, learns from experience |\n",
    "| **Autonomy** | Requires explicit commands | Self-directed toward goals |\n",
    "| **Complexity** | Handles specific tasks | Handles open-ended problems |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b702b97",
   "metadata": {},
   "source": [
    "### Deep Dive: Understanding Each Component\n",
    "\n",
    "Let's break down each part of the agent loop in detail:\n",
    "\n",
    "#### 1ï¸âƒ£ **PERCEIVE** - Gathering Information\n",
    "\n",
    "The agent's first job is to understand what's happening. This is where sensors come in.\n",
    "\n",
    "**Sensors can be:**\n",
    "- Physical: Cameras, microphones, temperature sensors\n",
    "- Digital: API calls, database queries, user input\n",
    "- Abstract: Text prompts, structured data, event streams\n",
    "\n",
    "**Example Perceptions:**\n",
    "```\n",
    "Robot perceives: \"Obstacle 2 meters ahead, battery 75%, target location 10 meters north\"\n",
    "Chess AI perceives: \"Your queen is under attack, opponent has 3 pieces to your 4\"\n",
    "Chatbot perceives: \"User asked about pricing in a confused tone\"\n",
    "```\n",
    "\n",
    "**Key insight**: Good perception requires filtering noise and extracting relevant information.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2ï¸âƒ£ **REASON** - Making Decisions\n",
    "\n",
    "Now the agent thinks about what the perception means and what to do.\n",
    "\n",
    "**Types of reasoning:**\n",
    "- **Rule-based**: \"IF temperature < 20 THEN heat\"\n",
    "- **Learning-based**: Neural network trained on past experiences\n",
    "- **Search-based**: Explore possible actions and pick the best\n",
    "- **Probabilistic**: Account for uncertainty and risk\n",
    "\n",
    "**Example Reasoning:**\n",
    "```\n",
    "Thermostat: \"Temperature is 18Â°C, target is 20Â°C â†’ Decision: TURN ON HEATER\"\n",
    "Chess AI: \"Current position is bad â†’ Search for better moves â†’ MOVE QUEEN TO E4\"\n",
    "Chatbot: \"User is confused â†’ Recommendation: PROVIDE MORE DETAILS\"\n",
    "```\n",
    "\n",
    "**Key insight**: Better reasoning = better decisions, but often slower.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3ï¸âƒ£ **ACT** - Taking Action\n",
    "\n",
    "The agent executes its decision through actuators.\n",
    "\n",
    "**Actuators can be:**\n",
    "- Physical: Motors, speakers, lights, doors\n",
    "- Digital: API calls, database updates, network messages\n",
    "- Interactive: Display changes, notifications, messages\n",
    "\n",
    "**Example Actions:**\n",
    "```\n",
    "Thermostat: Activates heating system for 5 minutes\n",
    "Chess AI: Moves piece from B1 to E4 and waits for opponent\n",
    "Chatbot: Sends a detailed response explaining the pricing\n",
    "```\n",
    "\n",
    "**Key insight**: Incomplete or slow actions can break the loop.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4ï¸âƒ£ **LEARN** - Improving Over Time\n",
    "\n",
    "The agent observes the outcome and updates its knowledge.\n",
    "\n",
    "**What agents learn:**\n",
    "- Which actions led to good/bad outcomes\n",
    "- Patterns in the environment\n",
    "- Better ways to reach goals\n",
    "- Parameters to tune future decisions\n",
    "\n",
    "**Example Learning:**\n",
    "```\n",
    "Thermostat: \"Heating for 5 min raised temp by 2Â°C â†’ remember this ratio\"\n",
    "Chess AI: \"This move lost the queen â†’ avoid similar positions\"\n",
    "Chatbot: \"This response got positive feedback â†’ use similar language\"\n",
    "```\n",
    "\n",
    "**Key insight**: Learning takes time but enables long-term improvement.\n",
    "\n",
    "---\n",
    "\n",
    "### The Complete Cycle\n",
    "\n",
    "All four steps together create the agent loop:\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚          START OF AGENT CYCLE                â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  1. PERCEIVE environment                     â”‚\n",
    "â”‚     â””â”€ Get sensor data â†’ Extract meaning     â”‚\n",
    "â”‚                    â†“                          â”‚\n",
    "â”‚  2. REASON about situation                   â”‚\n",
    "â”‚     â””â”€ Apply logic â†’ Generate decision       â”‚\n",
    "â”‚                    â†“                          â”‚\n",
    "â”‚  3. ACT on decision                          â”‚\n",
    "â”‚     â””â”€ Activate actuators â†’ Change world     â”‚\n",
    "â”‚                    â†“                          â”‚\n",
    "â”‚  4. LEARN from outcome                       â”‚\n",
    "â”‚     â””â”€ Observe result â†’ Update knowledge     â”‚\n",
    "â”‚                    â†“                          â”‚\n",
    "â”‚          REPEAT NEXT CYCLE                   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "This loop can run:\n",
    "- **Seconds**: Reactive agents responding instantly\n",
    "- **Minutes**: Deliberative agents planning\n",
    "- **Hours/Days**: Learning agents accumulating experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafb857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive: Agent Loop Visualization\n",
    "# Let's visualize the agent loop with an example\n",
    "\n",
    "from IPython.display import display, Markdown, HTML\n",
    "import time\n",
    "\n",
    "def visualize_agent_loop(environment_state, agent_name=\"My Agent\"):\n",
    "    \"\"\"Demonstrate the agent feedback loop step by step\"\"\"\n",
    "    \n",
    "    steps = [\n",
    "        {\n",
    "            \"phase\": \"1ï¸âƒ£ PERCEIVE\",\n",
    "            \"description\": \"Agent observes the environment\",\n",
    "            \"example\": f\"Sensor input: {environment_state}\"\n",
    "        },\n",
    "        {\n",
    "            \"phase\": \"2ï¸âƒ£ REASON\",\n",
    "            \"description\": \"Agent analyzes information and makes decisions\",\n",
    "            \"example\": f\"Decision logic: If '{environment_state}' then action = ?\"\n",
    "        },\n",
    "        {\n",
    "            \"phase\": \"3ï¸âƒ£ ACT\",\n",
    "            \"description\": \"Agent takes an action to affect the environment\",\n",
    "            \"example\": \"Action taken: Adjust behavior based on analysis\"\n",
    "        },\n",
    "        {\n",
    "            \"phase\": \"4ï¸âƒ£ LEARN\",\n",
    "            \"description\": \"Agent updates its knowledge from the outcome\",\n",
    "            \"example\": \"Update: This action produced a certain result\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nğŸ¤– {agent_name} - Agent Loop Demonstration\\n\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for step in steps:\n",
    "        print(f\"\\n{step['phase']}\")\n",
    "        print(f\"â””â”€ {step['description']}\")\n",
    "        print(f\"   Example: {step['example']}\")\n",
    "        print()\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"âœ… Loop complete - agent is ready for next cycle!\\n\")\n",
    "\n",
    "# Run the visualization\n",
    "visualize_agent_loop(\"obstacle detected\", \"Robot Navigation Agent\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a883b3",
   "metadata": {},
   "source": [
    "## 2. Types of AI Agents\n",
    "\n",
    "Agents come in different flavors based on their decision-making complexity:\n",
    "\n",
    "### Reactive Agents\n",
    "- **How they work**: Directly map percepts to actions (stimulus â†’ response)\n",
    "- **Pros**: Fast, simple, predictable\n",
    "- **Cons**: No memory, can't handle complex scenarios\n",
    "- **Example**: Thermostat that turns heating on/off based on temperature\n",
    "\n",
    "### Deliberative Agents\n",
    "- **How they work**: Use reasoning with planning and world models\n",
    "- **Pros**: Handle complex goals, can plan ahead\n",
    "- **Cons**: Slower, computationally expensive\n",
    "- **Example**: Chess engine that thinks multiple moves ahead\n",
    "\n",
    "### Hybrid Agents\n",
    "- **How they work**: Combine reactive speed with deliberative reasoning\n",
    "- **Pros**: Fast responses + smart planning\n",
    "- **Cons**: More complex to implement\n",
    "- **Example**: Self-driving car (reacts to obstacles instantly, plans routes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849521f0",
   "metadata": {},
   "source": [
    "#### Detailed Comparison\n",
    "\n",
    "**Reactive Agents Deep Dive:**\n",
    "\n",
    "These are the simplest agents. They directly map inputs to outputs without any internal state.\n",
    "\n",
    "```\n",
    "Input â†’ Condition Check â†’ Output\n",
    "```\n",
    "\n",
    "Pros:\n",
    "- âœ… Extremely fast (milliseconds)\n",
    "- âœ… Predictable behavior\n",
    "- âœ… Easy to understand and debug\n",
    "- âœ… Work well for simple, well-defined problems\n",
    "\n",
    "Cons:\n",
    "- âŒ Can't handle complex scenarios\n",
    "- âŒ No memory - can't learn\n",
    "- âŒ No planning - can't handle long-term goals\n",
    "\n",
    "Real-world examples:\n",
    "- Thermostats (too hot â†’ cool, too cold â†’ heat)\n",
    "- Traffic lights (sensor input â†’ color change)\n",
    "- Ant colonies (no individual planning, pure stimulus-response)\n",
    "\n",
    "---\n",
    "\n",
    "**Deliberative Agents Deep Dive:**\n",
    "\n",
    "These agents think ahead. They build a model of the world and plan their actions.\n",
    "\n",
    "```\n",
    "Sensors â†’ World Model â†’ Planning â†’ Action Execution\n",
    "```\n",
    "\n",
    "Pros:\n",
    "- âœ… Can handle complex goals\n",
    "- âœ… Can plan multiple steps ahead\n",
    "- âœ… Understand consequences\n",
    "- âœ… Adapt to new situations\n",
    "\n",
    "Cons:\n",
    "- âŒ Slower (seconds to minutes)\n",
    "- âŒ Require accurate world models\n",
    "- âŒ Computationally expensive\n",
    "- âŒ Can be over-confident in wrong models\n",
    "\n",
    "Real-world examples:\n",
    "- Chess engines (think 10+ moves ahead)\n",
    "- Route planners (calculate best path)\n",
    "- Scientific researchers (plan experiments)\n",
    "\n",
    "---\n",
    "\n",
    "**Hybrid Agents Deep Dive:**\n",
    "\n",
    "Best of both worlds! Quick reactive layer + smart deliberative layer.\n",
    "\n",
    "```\n",
    "Quick reactions (reactive layer) + Careful planning (deliberative layer)\n",
    "```\n",
    "\n",
    "Architecture:\n",
    "```\n",
    "Sensors\n",
    "  â†“\n",
    "Reactive Layer (fast, responds to emergencies)\n",
    "  â†“\n",
    "Deliberative Layer (slow, plans long-term)\n",
    "  â†“\n",
    "Decision Merger (combines both recommendations)\n",
    "  â†“\n",
    "Actuators\n",
    "```\n",
    "\n",
    "Pros:\n",
    "- âœ… Fast emergency responses\n",
    "- âœ… Smart long-term planning\n",
    "- âœ… Balances speed and quality\n",
    "- âœ… Handles unpredictable environments\n",
    "\n",
    "Cons:\n",
    "- âš ï¸ More complex to implement\n",
    "- âš ï¸ Need to balance both layers\n",
    "- âš ï¸ Can have conflicts between layers\n",
    "\n",
    "Real-world examples:\n",
    "- Self-driving cars (avoid crash immediately, plan route slowly)\n",
    "- Robots (dodge obstacle quickly, navigate to goal)\n",
    "- Video game NPCs (flee from danger, pursue long-term quests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a86baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive: Agent Type Explorer\n",
    "# Try different agent types and see their characteristics\n",
    "\n",
    "from ipywidgets import interactive, RadioButtons, IntSlider, Output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "agent_types = {\n",
    "    \"Reactive\": {\n",
    "        \"description\": \"Direct stimulus-response\",\n",
    "        \"speed\": \"âš¡ Very Fast\",\n",
    "        \"memory\": \"None\",\n",
    "        \"planning\": \"None\",\n",
    "        \"example\": \"Ant colony behavior, simple robots\",\n",
    "        \"code_example\": \"if temperature > 25:\\n    turn_ac_on()\"\n",
    "    },\n",
    "    \"Deliberative\": {\n",
    "        \"description\": \"Planning-based decision making\",\n",
    "        \"speed\": \"ğŸ¢ Slow\",\n",
    "        \"memory\": \"Full world model\",\n",
    "        \"planning\": \"Extensive\",\n",
    "        \"example\": \"Chess AI, route planning\",\n",
    "        \"code_example\": \"plan = search_for_goal(world_model)\\nexecute_plan(plan)\"\n",
    "    },\n",
    "    \"Hybrid\": {\n",
    "        \"description\": \"Reactive layer + deliberative layer\",\n",
    "        \"speed\": \"âš¡ Fast with planning\",\n",
    "        \"memory\": \"Selective memory\",\n",
    "        \"planning\": \"Strategic\",\n",
    "        \"example\": \"Self-driving cars, game AI\",\n",
    "        \"code_example\": \"react_to_immediate_threats()\\nplan_long_term_strategy()\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def show_agent_type(agent_type):\n",
    "    info = agent_types[agent_type]\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ğŸ¤– {agent_type.upper()} AGENT\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Description: {info['description']}\")\n",
    "    print(f\"Speed: {info['speed']}\")\n",
    "    print(f\"Memory: {info['memory']}\")\n",
    "    print(f\"Planning Capability: {info['planning']}\")\n",
    "    print(f\"Real-world Example: {info['example']}\")\n",
    "    print(f\"\\nCode Pattern:\")\n",
    "    print(f\"```python\")\n",
    "    print(info['code_example'])\n",
    "    print(f\"```\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Create interactive widget\n",
    "agent_selector = RadioButtons(\n",
    "    options=[\"Reactive\", \"Deliberative\", \"Hybrid\"],\n",
    "    value=\"Reactive\",\n",
    "    description='Choose Agent Type:'\n",
    ")\n",
    "\n",
    "interactive(show_agent_type, agent_type=agent_selector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282925e5",
   "metadata": {},
   "source": [
    "## 3. Agent Architecture and Components\n",
    "\n",
    "Every agent has core components that work together:\n",
    "\n",
    "### The Four Essential Components\n",
    "\n",
    "#### 1. **Sensors** (Perception Module)\n",
    "- Collect information from the environment\n",
    "- Convert real-world signals into data the agent understands\n",
    "- Examples: cameras, temperature sensors, user input, APIs\n",
    "\n",
    "#### 2. **Decision Engine** (Brain)\n",
    "- Processes sensor data using rules, ML models, or reasoning algorithms\n",
    "- Decides what action to take based on goals and constraints\n",
    "- Examples: neural networks, decision trees, logic systems\n",
    "\n",
    "#### 3. **Actuators** (Action Module)\n",
    "- Execute decisions in the physical or digital world\n",
    "- Convert agent decisions into environmental changes\n",
    "- Examples: motors, displays, API calls, network requests\n",
    "\n",
    "#### 4. **Memory** (Knowledge Base)\n",
    "- Stores past experiences and learned information\n",
    "- Enables agents to recognize patterns and improve over time\n",
    "- Examples: experience history, learned models, world state representation\n",
    "\n",
    "### How They Connect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6458c0",
   "metadata": {},
   "source": [
    "#### In-Depth Component Analysis\n",
    "\n",
    "**Sensors (Input Layer)**\n",
    "\n",
    "Sensors are the agent's way of perceiving the world. Without good sensors, agents are blind.\n",
    "\n",
    "*Types of sensors:*\n",
    "1. **Visual**: Cameras, image data\n",
    "   - Used in: Robotics, computer vision systems\n",
    "   - Challenge: High-dimensional data, real-time processing\n",
    "\n",
    "2. **Textual**: Natural language input, text data\n",
    "   - Used in: Chatbots, NLP systems\n",
    "   - Challenge: Ambiguity, context understanding\n",
    "\n",
    "3. **Numerical**: Measurements, sensor readings, API data\n",
    "   - Used in: IoT, trading systems, monitoring\n",
    "   - Challenge: Noise filtering, outlier detection\n",
    "\n",
    "4. **Structured**: Databases, logs, events\n",
    "   - Used in: Enterprise systems, analytics\n",
    "   - Challenge: Missing data, inconsistencies\n",
    "\n",
    "*Sensor challenges:*\n",
    "- Noise: Real-world sensors have errors\n",
    "- Latency: Delay between event and perception\n",
    "- Cost: Expensive or unavailable sensors\n",
    "- Privacy: What data can we collect?\n",
    "\n",
    "---\n",
    "\n",
    "**Decision Engine (Processing Layer)**\n",
    "\n",
    "The decision engine is the \"brain\" - where reasoning happens.\n",
    "\n",
    "*Decision methods:*\n",
    "1. **Rules-based**: Hard-coded IF-THEN rules\n",
    "   ```\n",
    "   IF temperature > 25 AND humidity > 80\n",
    "   THEN activate AC with high power\n",
    "   ```\n",
    "   - Fast, predictable\n",
    "   - Limited to pre-written rules\n",
    "\n",
    "2. **Decision Trees**: Hierarchical decisions\n",
    "   ```\n",
    "   IF sensor1 > threshold?\n",
    "   â”œâ”€ YES: IF sensor2 > threshold?\n",
    "   â”‚       â”œâ”€ YES: Action A\n",
    "   â”‚       â””â”€ NO: Action B\n",
    "   â””â”€ NO: Action C\n",
    "   ```\n",
    "   - Interpretable\n",
    "   - Works well for categorical decisions\n",
    "\n",
    "3. **Neural Networks**: Learning-based decisions\n",
    "   ```\n",
    "   Input â†’ Hidden Layers â†’ Output\n",
    "   ```\n",
    "   - Learns patterns from data\n",
    "   - Black box (hard to explain)\n",
    "\n",
    "4. **Probabilistic**: Handles uncertainty\n",
    "   ```\n",
    "   Decision = argmax P(action | state)\n",
    "   ```\n",
    "   - Accounts for uncertainty\n",
    "   - Computationally complex\n",
    "\n",
    "---\n",
    "\n",
    "**Actuators (Output Layer)**\n",
    "\n",
    "Actuators execute decisions - they're the agent's hands/voice/movement.\n",
    "\n",
    "*Types of actuators:*\n",
    "1. **Physical**: Motors, pumps, heaters\n",
    "   - Robot arm movement, vehicle control\n",
    "\n",
    "2. **Digital**: API calls, network requests, database writes\n",
    "   - Send alerts, store results, trigger external systems\n",
    "\n",
    "3. **Interactive**: Display changes, messages, notifications\n",
    "   - Show results to humans, request input\n",
    "\n",
    "4. **Abstract**: Model updates, knowledge modifications\n",
    "   - Update internal understanding\n",
    "\n",
    "*Actuator challenges:*\n",
    "- Precision: Can we execute the exact action needed?\n",
    "- Responsiveness: How long does execution take?\n",
    "- Reliability: What if actuators fail?\n",
    "- Cost: How much power/resources needed?\n",
    "\n",
    "---\n",
    "\n",
    "**Memory (Knowledge Store)**\n",
    "\n",
    "Memory allows agents to learn and accumulate experience.\n",
    "\n",
    "*Types of memory:*\n",
    "1. **Episodic**: \"What happened?\"\n",
    "   - History of past events\n",
    "   - Used for: Learning patterns, remembering mistakes\n",
    "\n",
    "2. **Semantic**: \"What do I know?\"\n",
    "   - Facts, concepts, relationships\n",
    "   - Used for: Reasoning, planning\n",
    "\n",
    "3. **Procedural**: \"How do I do things?\"\n",
    "   - Skills, learned behaviors\n",
    "   - Used for: Executing complex tasks\n",
    "\n",
    "4. **State**: \"What's the current situation?\"\n",
    "   - Current beliefs, goals, progress\n",
    "   - Used for: Making decisions\n",
    "\n",
    "*Memory challenges:*\n",
    "- Storage: How much can we store?\n",
    "- Recall: Can we find what we need?\n",
    "- Forgetting: What should we remove?\n",
    "- Updating: How do we change beliefs with new info?\n",
    "\n",
    "---\n",
    "\n",
    "**How Components Work Together**\n",
    "\n",
    "A complete agent flow:\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  SENSOR receives input                              â”‚\n",
    "â”‚  â””â”€â†’ \"Temperature: 18Â°C, Target: 20Â°C\"              â”‚\n",
    "â”‚                    â†“                                  â”‚\n",
    "â”‚  MEMORY retrieves relevant knowledge                 â”‚\n",
    "â”‚  â””â”€â†’ \"Past experience: 1Â°C = 5 min of heating\"      â”‚\n",
    "â”‚                    â†“                                  â”‚\n",
    "â”‚  DECISION ENGINE processes                          â”‚\n",
    "â”‚  â””â”€â†’ \"Too cold, heat for expected 10 minutes\"       â”‚\n",
    "â”‚                    â†“                                  â”‚\n",
    "â”‚  ACTUATOR executes                                  â”‚\n",
    "â”‚  â””â”€â†’ \"Turn on heater at 80% power\"                  â”‚\n",
    "â”‚                    â†“                                  â”‚\n",
    "â”‚  SENSOR observes outcome                            â”‚\n",
    "â”‚  â””â”€â†’ \"Temperature rising to 19Â°C, 20Â°C in 9 min\"   â”‚\n",
    "â”‚                    â†“                                  â”‚\n",
    "â”‚  MEMORY updates                                      â”‚\n",
    "â”‚  â””â”€â†’ \"Reality: 1Â°C = 4.5 min of heating\"           â”‚\n",
    "â”‚                    â†“                                  â”‚\n",
    "â”‚  NEXT CYCLE: Better knowledge, better decisions     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "This integration is what makes agents powerful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd4c954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive: Build and Visualize an Agent Architecture\n",
    "# Toggle components on/off to see how they interact\n",
    "\n",
    "from ipywidgets import Checkbox, HBox, VBox, Output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "class AgentComponent:\n",
    "    def __init__(self, name, description, icon):\n",
    "        self.name = name\n",
    "        self.description = description\n",
    "        self.icon = icon\n",
    "        self.enabled = True\n",
    "\n",
    "# Define components\n",
    "components = {\n",
    "    \"sensors\": AgentComponent(\"Sensors\", \"Perceives environment (cameras, data, APIs)\", \"ğŸ‘ï¸\"),\n",
    "    \"memory\": AgentComponent(\"Memory\", \"Stores experiences and learned patterns\", \"ğŸ§ \"),\n",
    "    \"decision\": AgentComponent(\"Decision Engine\", \"Processes info and chooses actions\", \"âš™ï¸\"),\n",
    "    \"actuators\": AgentComponent(\"Actuators\", \"Executes actions in the world\", \"ğŸ’ª\")\n",
    "}\n",
    "\n",
    "output = Output()\n",
    "\n",
    "def visualize_architecture(show_sensors, show_memory, show_decision, show_actuators):\n",
    "    with output:\n",
    "        output.clear()\n",
    "        \n",
    "        enabled = {\n",
    "            \"sensors\": show_sensors,\n",
    "            \"memory\": show_memory,\n",
    "            \"decision\": show_decision,\n",
    "            \"actuators\": show_actuators\n",
    "        }\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ğŸ—ï¸  AGENT ARCHITECTURE VISUALIZATION\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "        \n",
    "        # Visualization\n",
    "        active_components = []\n",
    "        \n",
    "        if enabled[\"sensors\"]:\n",
    "            active_components.append(\"ğŸ‘ï¸  SENSORS â†’ Read environment\")\n",
    "        if enabled[\"memory\"]:\n",
    "            active_components.append(\"ğŸ§   MEMORY â† Store experiences\")\n",
    "        if enabled[\"decision\"]:\n",
    "            active_components.append(\"âš™ï¸  DECISION ENGINE â† Process & decide\")\n",
    "        if enabled[\"actuators\"]:\n",
    "            active_components.append(\"ğŸ’ª  ACTUATORS â† Execute actions\")\n",
    "        \n",
    "        if not active_components:\n",
    "            print(\"âŒ Select at least one component!\")\n",
    "        else:\n",
    "            for comp in active_components:\n",
    "                print(comp)\n",
    "            \n",
    "            print(\"\\n\" + \"-\"*60)\n",
    "            print(\"Flow: \", end=\"\")\n",
    "            \n",
    "            flow_parts = []\n",
    "            if enabled[\"sensors\"]:\n",
    "                flow_parts.append(\"Percept\")\n",
    "            if enabled[\"decision\"]:\n",
    "                flow_parts.append(\"Decide\")\n",
    "            if enabled[\"actuators\"]:\n",
    "                flow_parts.append(\"Act\")\n",
    "            if enabled[\"memory\"]:\n",
    "                flow_parts.append(\"Learn\")\n",
    "            \n",
    "            print(\" â†’ \".join(flow_parts))\n",
    "            print(\"-\"*60 + \"\\n\")\n",
    "            \n",
    "            # Show status\n",
    "            print(\"âœ… Agent is ACTIVE\" if all(enabled.values()) else \"âš ï¸  Agent is INCOMPLETE\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Create checkboxes\n",
    "checkboxes = VBox([\n",
    "    Checkbox(value=True, description='Sensors'),\n",
    "    Checkbox(value=True, description='Memory'),\n",
    "    Checkbox(value=True, description='Decision Engine'),\n",
    "    Checkbox(value=True, description='Actuators'),\n",
    "])\n",
    "\n",
    "# Create interactive visualization\n",
    "interactive_plot = interactive(\n",
    "    visualize_architecture,\n",
    "    show_sensors=checkboxes.children[0],\n",
    "    show_memory=checkboxes.children[1],\n",
    "    show_decision=checkboxes.children[2],\n",
    "    show_actuators=checkboxes.children[3]\n",
    ")\n",
    "\n",
    "display(VBox([\n",
    "    widgets.HTML(\"<b>Toggle components to see architecture:</b>\"),\n",
    "    checkboxes,\n",
    "    output\n",
    "]))\n",
    "\n",
    "# Run initial visualization\n",
    "visualize_architecture(True, True, True, True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b39490",
   "metadata": {},
   "source": [
    "## 4. Building a Simple Reactive Agent\n",
    "\n",
    "Let's build our first agent! We'll create a **smart thermostat agent** that maintains room temperature.\n",
    "\n",
    "### The Agent's Task:\n",
    "- **Goal**: Keep room temperature between 20-25Â°C\n",
    "- **Type**: Reactive agent (direct stimulus-response)\n",
    "- **Sensors**: Temperature sensor\n",
    "- **Actuators**: Heater and AC unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b72c450",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThermostatAgent:\n",
    "    \"\"\"\n",
    "    A simple reactive agent that controls room temperature.\n",
    "    \n",
    "    This agent:\n",
    "    1. Perceives the current temperature\n",
    "    2. Decides what to do based on rules\n",
    "    3. Acts by turning heating/cooling on or off\n",
    "    4. Learns nothing (reactive agent)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, target_min=20, target_max=25):\n",
    "        self.target_min = target_min\n",
    "        self.target_max = target_max\n",
    "        self.heating_on = False\n",
    "        self.cooling_on = False\n",
    "        self.action_history = []\n",
    "    \n",
    "    def perceive(self, current_temp):\n",
    "        \"\"\"Step 1: Sense the environment\"\"\"\n",
    "        return current_temp\n",
    "    \n",
    "    def decide(self, current_temp):\n",
    "        \"\"\"Step 2: Use rules to decide what to do\"\"\"\n",
    "        \n",
    "        if current_temp < self.target_min:\n",
    "            return \"HEAT\"\n",
    "        elif current_temp > self.target_max:\n",
    "            return \"COOL\"\n",
    "        else:\n",
    "            return \"IDLE\"\n",
    "    \n",
    "    def act(self, action):\n",
    "        \"\"\"Step 3: Execute the action\"\"\"\n",
    "        \n",
    "        if action == \"HEAT\":\n",
    "            self.heating_on = True\n",
    "            self.cooling_on = False\n",
    "            effect = \"ğŸ”¥ Heating turned ON\"\n",
    "        elif action == \"COOL\":\n",
    "            self.heating_on = False\n",
    "            self.cooling_on = True\n",
    "            effect = \"â„ï¸  Cooling turned ON\"\n",
    "        else:\n",
    "            self.heating_on = False\n",
    "            self.cooling_on = False\n",
    "            effect = \"âœ… Both systems OFF (comfortable!)\"\n",
    "        \n",
    "        self.action_history.append(action)\n",
    "        return effect\n",
    "    \n",
    "    def run(self, current_temp):\n",
    "        \"\"\"Execute one complete agent cycle: Perceive â†’ Decide â†’ Act\"\"\"\n",
    "        \n",
    "        percept = self.perceive(current_temp)\n",
    "        action = self.decide(percept)\n",
    "        effect = self.act(action)\n",
    "        \n",
    "        return {\n",
    "            \"temperature\": percept,\n",
    "            \"decision\": action,\n",
    "            \"effect\": effect\n",
    "        }\n",
    "\n",
    "# Create an agent instance\n",
    "thermostat = ThermostatAgent()\n",
    "\n",
    "print(\"ğŸ  Smart Thermostat Agent Demo\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Target Temperature Range: 20-25Â°C\\n\")\n",
    "\n",
    "# Test the agent with different temperatures\n",
    "test_temps = [18, 20, 22, 25, 28, 25, 22]\n",
    "\n",
    "for temp in test_temps:\n",
    "    result = thermostat.run(temp)\n",
    "    print(f\"Current Temp: {result['temperature']}Â°C\")\n",
    "    print(f\"Decision: {result['decision']}\")\n",
    "    print(f\"Action: {result['effect']}\")\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total actions taken: {len(thermostat.action_history)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea61d15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive: Customize the Thermostat Agent!\n",
    "# Modify the temperature thresholds and see how the agent responds\n",
    "\n",
    "from ipywidgets import FloatSlider, Button, Output, VBox, HBox\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Create sliders for user input\n",
    "min_temp_slider = FloatSlider(\n",
    "    value=20,\n",
    "    min=15,\n",
    "    max=25,\n",
    "    step=0.5,\n",
    "    description='Min Temp (Â°C):',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "max_temp_slider = FloatSlider(\n",
    "    value=25,\n",
    "    min=20,\n",
    "    max=30,\n",
    "    step=0.5,\n",
    "    description='Max Temp (Â°C):',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "current_temp_slider = FloatSlider(\n",
    "    value=22,\n",
    "    min=15,\n",
    "    max=35,\n",
    "    step=0.5,\n",
    "    description='Current Temp (Â°C):',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "output = Output()\n",
    "\n",
    "def test_thermostat(min_temp, max_temp, current_temp):\n",
    "    with output:\n",
    "        output.clear()\n",
    "        \n",
    "        # Validate inputs\n",
    "        if min_temp >= max_temp:\n",
    "            print(\"âŒ Error: Min temperature must be less than Max!\")\n",
    "            return\n",
    "        \n",
    "        # Create agent with custom parameters\n",
    "        agent = ThermostatAgent(target_min=min_temp, target_max=max_temp)\n",
    "        \n",
    "        # Run the agent\n",
    "        result = agent.run(current_temp)\n",
    "        \n",
    "        # Display results\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ğŸ¤– AGENT RESPONSE\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"ğŸ“Š Target Range: {min_temp}Â°C - {max_temp}Â°C\")\n",
    "        print(f\"ğŸ“ˆ Current Temp: {current_temp}Â°C\")\n",
    "        print(f\"\\nğŸ§  Agent's Decision: {result['decision']}\")\n",
    "        print(f\"âš¡ Action Taken: {result['effect']}\")\n",
    "        \n",
    "        # Show reasoning\n",
    "        print(\"\\nğŸ“ Agent Reasoning:\")\n",
    "        if current_temp < min_temp:\n",
    "            temp_diff = min_temp - current_temp\n",
    "            print(f\"   â†’ Too cold by {temp_diff:.1f}Â°C â†’ Activate heating!\")\n",
    "        elif current_temp > max_temp:\n",
    "            temp_diff = current_temp - max_temp\n",
    "            print(f\"   â†’ Too hot by {temp_diff:.1f}Â°C â†’ Activate cooling!\")\n",
    "        else:\n",
    "            print(f\"   â†’ Temperature is in comfort zone â†’ No action needed!\")\n",
    "        \n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Create interactive layout\n",
    "test_button = Button(description='Test Agent', button_style='info')\n",
    "\n",
    "def on_test_click(b):\n",
    "    test_thermostat(\n",
    "        min_temp_slider.value,\n",
    "        max_temp_slider.value,\n",
    "        current_temp_slider.value\n",
    "    )\n",
    "\n",
    "test_button.on_click(on_test_click)\n",
    "\n",
    "# Display controls\n",
    "display(VBox([\n",
    "    widgets.HTML(\"<b style='font-size: 14px;'>âš™ï¸ Configure Your Thermostat Agent</b>\"),\n",
    "    min_temp_slider,\n",
    "    max_temp_slider,\n",
    "    current_temp_slider,\n",
    "    test_button,\n",
    "    output\n",
    "]))\n",
    "\n",
    "# Run initial test\n",
    "test_thermostat(20, 25, 22)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb32825",
   "metadata": {},
   "source": [
    "## 5. Interactive Agent Simulation\n",
    "\n",
    "Now let's run a **full environmental simulation** where we can observe the agent operating over time. You can control the environment and watch the agent respond in real-time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db55ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ipywidgets import IntSlider, Dropdown, Button, Output, VBox, HBox\n",
    "import ipywidgets as widgets\n",
    "\n",
    "class EnvironmentSimulator:\n",
    "    \"\"\"Simulates an environment with temperature changes\"\"\"\n",
    "    \n",
    "    def __init__(self, initial_temp=22, external_pattern=\"stable\"):\n",
    "        self.initial_temp = initial_temp\n",
    "        self.current_temp = initial_temp\n",
    "        self.external_pattern = external_pattern\n",
    "        self.step = 0\n",
    "        self.temperatures = [initial_temp]\n",
    "        self.actions = []\n",
    "        self.agent = ThermostatAgent()\n",
    "    \n",
    "    def get_external_temp_change(self):\n",
    "        \"\"\"Simulate external temperature changes based on pattern\"\"\"\n",
    "        \n",
    "        if self.external_pattern == \"stable\":\n",
    "            return 0\n",
    "        elif self.external_pattern == \"warming\":\n",
    "            return 0.3  # Gradual warming\n",
    "        elif self.external_pattern == \"cooling\":\n",
    "            return -0.3  # Gradual cooling\n",
    "        elif self.external_pattern == \"chaotic\":\n",
    "            return np.sin(self.step * 0.5) * 2  # Sine wave pattern\n",
    "        elif self.external_pattern == \"morning\":\n",
    "            # Simulates waking up at 6am and heating/cooling throughout day\n",
    "            return 0.5 * np.sin((self.step - 6) * np.pi / 12)\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def step_simulation(self):\n",
    "        \"\"\"Run one step of the simulation\"\"\"\n",
    "        \n",
    "        # Apply external temperature change\n",
    "        external_change = self.get_external_temp_change()\n",
    "        self.current_temp += external_change\n",
    "        \n",
    "        # Apply agent actions\n",
    "        result = self.agent.run(self.current_temp)\n",
    "        \n",
    "        # Apply system effects (heating/cooling impacts)\n",
    "        if self.agent.heating_on:\n",
    "            self.current_temp += 0.8  # Heating warms up the room\n",
    "        elif self.agent.cooling_on:\n",
    "            self.current_temp -= 0.8  # Cooling cools down the room\n",
    "        \n",
    "        # Add some noise\n",
    "        self.current_temp += np.random.normal(0, 0.1)\n",
    "        \n",
    "        self.temperatures.append(self.current_temp)\n",
    "        self.actions.append(result['decision'])\n",
    "        self.step += 1\n",
    "    \n",
    "    def run_simulation(self, num_steps):\n",
    "        \"\"\"Run multiple steps and return data\"\"\"\n",
    "        \n",
    "        self.temperatures = [self.initial_temp]\n",
    "        self.actions = []\n",
    "        self.step = 0\n",
    "        \n",
    "        for _ in range(num_steps):\n",
    "            self.step_simulation()\n",
    "        \n",
    "        return self.temperatures, self.actions\n",
    "\n",
    "# Create simulation controls\n",
    "num_steps_slider = IntSlider(\n",
    "    value=50,\n",
    "    min=10,\n",
    "    max=200,\n",
    "    step=10,\n",
    "    description='Simulation Steps:',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "pattern_dropdown = Dropdown(\n",
    "    options=['stable', 'warming', 'cooling', 'chaotic', 'morning'],\n",
    "    value='stable',\n",
    "    description='Environment:'\n",
    ")\n",
    "\n",
    "simulation_output = Output()\n",
    "\n",
    "def run_simulation(num_steps, pattern):\n",
    "    with simulation_output:\n",
    "        simulation_output.clear()\n",
    "        \n",
    "        # Run the simulation\n",
    "        sim = EnvironmentSimulator(initial_temp=22, external_pattern=pattern)\n",
    "        temps, actions = sim.run_simulation(num_steps)\n",
    "        \n",
    "        # Create visualization\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "        \n",
    "        # Plot 1: Temperature over time\n",
    "        steps = range(len(temps))\n",
    "        ax1.plot(steps, temps, 'b-', linewidth=2, label='Room Temperature')\n",
    "        ax1.axhline(y=20, color='r', linestyle='--', label='Min Target (20Â°C)')\n",
    "        ax1.axhline(y=25, color='g', linestyle='--', label='Max Target (25Â°C)')\n",
    "        ax1.fill_between(steps, 20, 25, alpha=0.2, color='green', label='Comfort Zone')\n",
    "        ax1.set_xlabel('Time Step')\n",
    "        ax1.set_ylabel('Temperature (Â°C)')\n",
    "        ax1.set_title(f'ğŸ  Thermostat Agent Simulation - {pattern.capitalize()} Environment')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 2: Agent actions over time\n",
    "        action_map = {'HEAT': 1, 'IDLE': 0, 'COOL': -1}\n",
    "        action_values = [action_map[a] for a in actions]\n",
    "        colors = ['red' if a == 1 else 'green' if a == -1 else 'blue' for a in action_values]\n",
    "        \n",
    "        ax2.bar(range(len(actions)), action_values, color=colors, alpha=0.7)\n",
    "        ax2.set_xlabel('Time Step')\n",
    "        ax2.set_ylabel('Action')\n",
    "        ax2.set_title('Agent Actions Over Time')\n",
    "        ax2.set_yticks([-1, 0, 1])\n",
    "        ax2.set_yticklabels(['Cool â„ï¸', 'Idle âœ…', 'Heat ğŸ”¥'])\n",
    "        ax2.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print statistics\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ğŸ“Š SIMULATION RESULTS\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Environment: {pattern.capitalize()}\")\n",
    "        print(f\"Total Steps: {len(temps)-1}\")\n",
    "        print(f\"\\nTemperature Statistics:\")\n",
    "        print(f\"  Min: {min(temps):.2f}Â°C\")\n",
    "        print(f\"  Max: {max(temps):.2f}Â°C\")\n",
    "        print(f\"  Avg: {np.mean(temps):.2f}Â°C\")\n",
    "        print(f\"  Std Dev: {np.std(temps):.2f}Â°C\")\n",
    "        \n",
    "        heat_count = actions.count('HEAT')\n",
    "        cool_count = actions.count('COOL')\n",
    "        idle_count = actions.count('IDLE')\n",
    "        \n",
    "        print(f\"\\nAgent Actions:\")\n",
    "        print(f\"  ğŸ”¥ Heating: {heat_count} times ({heat_count/len(actions)*100:.1f}%)\")\n",
    "        print(f\"  â„ï¸ Cooling: {cool_count} times ({cool_count/len(actions)*100:.1f}%)\")\n",
    "        print(f\"  âœ… Idle: {idle_count} times ({idle_count/len(actions)*100:.1f}%)\")\n",
    "        \n",
    "        # Calculate comfort\n",
    "        comfort_steps = sum(1 for t in temps if 20 <= t <= 25)\n",
    "        print(f\"\\nComfort Analysis:\")\n",
    "        print(f\"  Steps in comfort zone: {comfort_steps}/{len(temps)} ({comfort_steps/len(temps)*100:.1f}%)\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Create interactive layout\n",
    "run_button = Button(description='Run Simulation', button_style='success')\n",
    "\n",
    "def on_run_click(b):\n",
    "    run_simulation(num_steps_slider.value, pattern_dropdown.value)\n",
    "\n",
    "run_button.on_click(on_run_click)\n",
    "\n",
    "# Display controls\n",
    "display(VBox([\n",
    "    widgets.HTML(\"<b style='font-size: 14px;'>ğŸ”¬ Agent Simulation Control Panel</b>\"),\n",
    "    num_steps_slider,\n",
    "    pattern_dropdown,\n",
    "    run_button,\n",
    "    simulation_output\n",
    "]))\n",
    "\n",
    "# Run initial simulation\n",
    "run_simulation(50, 'stable')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7028ddc",
   "metadata": {},
   "source": [
    "## ğŸ“ Key Takeaways\n",
    "\n",
    "### What We Learned:\n",
    "\n",
    "1. **Agents are Autonomous Systems**\n",
    "   - They perceive, decide, and act without explicit human commands\n",
    "   - They operate in feedback loops, continuously adapting\n",
    "\n",
    "2. **Agent Types Vary in Complexity**\n",
    "   - Reactive: Fast, simple, no memory\n",
    "   - Deliberative: Smart planning, slower\n",
    "   - Hybrid: Best of both worlds\n",
    "\n",
    "3. **Components Work Together**\n",
    "   - Sensors gather data\n",
    "   - Decision engine processes it\n",
    "   - Actuators execute actions\n",
    "   - Memory enables learning\n",
    "\n",
    "4. **Agents Can Be Simple Yet Powerful**\n",
    "   - Even our basic thermostat agent makes intelligent decisions\n",
    "   - The power scales with more complex decision logic\n",
    "\n",
    "5. **Testing Reveals Agent Behavior**\n",
    "   - Simulations help us understand how agents adapt\n",
    "   - Different environments require different agent strategies\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- âœ… Understand what agents are\n",
    "- ğŸ¯ Next: Build a deliberative agent that plans ahead\n",
    "- ğŸ§  Then: Add learning to make agents improve over time\n",
    "- ğŸ¤ Finally: Create multi-agent systems\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’¡ Challenge Exercise\n",
    "\n",
    "**Modify the thermostat agent** to handle a new scenario:\n",
    "- Add a **\"weekend mode\"** where the target temperature range is different\n",
    "- Implement a **\"sleep mode\"** that's triggered at night\n",
    "- Make the agent **\"learn\"** from past experiences to improve comfort\n",
    "\n",
    "Try implementing one of these extensions in the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2240215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ Your Challenge: Extend the Thermostat Agent!\n",
    "# Uncomment one of the challenges below and implement it\n",
    "\n",
    "# CHALLENGE 1: Weekend Mode\n",
    "# ========================\n",
    "# Modify the ThermostatAgent class to support different temperature ranges\n",
    "# for weekdays vs weekends. The target range should change automatically.\n",
    "\n",
    "# def __init__(self, target_min_weekday=20, target_max_weekday=25,\n",
    "#              target_min_weekend=19, target_max_weekend=26):\n",
    "#     # Your code here\n",
    "#     pass\n",
    "\n",
    "# def is_weekend(self, hour):\n",
    "#     # Your code here: return True if it's weekend, False if weekday\n",
    "#     pass\n",
    "\n",
    "\n",
    "# CHALLENGE 2: Sleep Mode\n",
    "# =======================\n",
    "# Add a \"sleep mode\" that adjusts the target temperature range based on time\n",
    "# Sleep mode (10 PM - 6 AM): Target 18-22Â°C (cooler for better sleep)\n",
    "# Awake mode: Target 20-25Â°C (normal comfort zone)\n",
    "\n",
    "# def set_sleep_mode(self, is_sleeping):\n",
    "#     # Your code here\n",
    "#     pass\n",
    "\n",
    "\n",
    "# CHALLENGE 3: Learning from Experience\n",
    "# ======================================\n",
    "# Add memory to the agent so it learns which actions worked best\n",
    "# Track success: times when the agent achieved comfort zone with minimal action\n",
    "\n",
    "# def remember_outcome(self, action, result_temp):\n",
    "#     # Store this experience\n",
    "#     pass\n",
    "\n",
    "# def learn_optimal_action(self, current_temp):\n",
    "#     # Use past experience to make better decisions\n",
    "#     pass\n",
    "\n",
    "\n",
    "print(\"ğŸ¯ Ready to extend the agent?\")\n",
    "print(\"Choose a challenge above and implement your solution!\")\n",
    "print(\"\\nğŸ“š Hints:\")\n",
    "print(\"- Challenge 1: Use day of week to switch between configurations\")\n",
    "print(\"- Challenge 2: Add a mode parameter that affects decision logic\")\n",
    "print(\"- Challenge 3: Keep a history of (temperature, action, outcome) tuples\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
