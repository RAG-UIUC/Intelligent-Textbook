{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fcce97f",
   "metadata": {},
   "source": [
    "# Chapter 1: What Are AI Agents?\n",
    "\n",
    "## Welcome to Agentic Engineering! üöÄ\n",
    "\n",
    "In this chapter, we'll explore the fundamental concepts of AI agents‚Äîautonomous systems that perceive their environment, make decisions, and take actions to achieve goals. By the end, you'll understand how agents work and build your first interactive agent.\n",
    "\n",
    "> **Key Question**: What makes something an \"agent\" rather than just a program?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6032a30e",
   "metadata": {},
   "source": [
    "## 1. What Are AI Agents?\n",
    "\n",
    "### Definition\n",
    "An **AI agent** is an autonomous entity that:\n",
    "- **Perceives** its environment through sensors\n",
    "- **Reasons** about what to do based on goals and knowledge\n",
    "- **Acts** to change its environment through actuators\n",
    "- **Learns** and adapts from experience\n",
    "\n",
    "### The Agent Loop\n",
    "\n",
    "Every agent follows a continuous cycle:\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ        AGENT FEEDBACK LOOP              ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ  1. PERCEIVE: Gather environmental data ‚îÇ\n",
    "‚îÇ        ‚Üì                                  ‚îÇ\n",
    "‚îÇ  2. REASON: Process & decide             ‚îÇ\n",
    "‚îÇ        ‚Üì                                  ‚îÇ\n",
    "‚îÇ  3. ACT: Execute actions                 ‚îÇ\n",
    "‚îÇ        ‚Üì                                  ‚îÇ\n",
    "‚îÇ  4. LEARN: Update knowledge              ‚îÇ\n",
    "‚îÇ        ‚Üì (cycle repeats)                 ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "### What Makes an Agent Different?\n",
    "\n",
    "| Aspect | Traditional Program | AI Agent |\n",
    "|--------|-------------------|----------|\n",
    "| **Input** | Structured data | Sensors (camera, text, data) |\n",
    "| **Processing** | Fixed algorithms | Adaptive reasoning |\n",
    "| **Output** | Predetermined responses | Goal-oriented decisions |\n",
    "| **Adaptation** | Static | Dynamic, learns from experience |\n",
    "| **Autonomy** | Requires explicit commands | Self-directed toward goals |\n",
    "| **Complexity** | Handles specific tasks | Handles open-ended problems |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafb857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive: Agent Loop Visualization\n",
    "# Let's visualize the agent loop with an example\n",
    "\n",
    "from IPython.display import display, Markdown, HTML\n",
    "import time\n",
    "\n",
    "def visualize_agent_loop(environment_state, agent_name=\"My Agent\"):\n",
    "    \"\"\"Demonstrate the agent feedback loop step by step\"\"\"\n",
    "    \n",
    "    steps = [\n",
    "        {\n",
    "            \"phase\": \"1Ô∏è‚É£ PERCEIVE\",\n",
    "            \"description\": \"Agent observes the environment\",\n",
    "            \"example\": f\"Sensor input: {environment_state}\"\n",
    "        },\n",
    "        {\n",
    "            \"phase\": \"2Ô∏è‚É£ REASON\",\n",
    "            \"description\": \"Agent analyzes information and makes decisions\",\n",
    "            \"example\": f\"Decision logic: If '{environment_state}' then action = ?\"\n",
    "        },\n",
    "        {\n",
    "            \"phase\": \"3Ô∏è‚É£ ACT\",\n",
    "            \"description\": \"Agent takes an action to affect the environment\",\n",
    "            \"example\": \"Action taken: Adjust behavior based on analysis\"\n",
    "        },\n",
    "        {\n",
    "            \"phase\": \"4Ô∏è‚É£ LEARN\",\n",
    "            \"description\": \"Agent updates its knowledge from the outcome\",\n",
    "            \"example\": \"Update: This action produced a certain result\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nü§ñ {agent_name} - Agent Loop Demonstration\\n\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for step in steps:\n",
    "        print(f\"\\n{step['phase']}\")\n",
    "        print(f\"‚îî‚îÄ {step['description']}\")\n",
    "        print(f\"   Example: {step['example']}\")\n",
    "        print()\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"‚úÖ Loop complete - agent is ready for next cycle!\\n\")\n",
    "\n",
    "# Run the visualization\n",
    "visualize_agent_loop(\"obstacle detected\", \"Robot Navigation Agent\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a883b3",
   "metadata": {},
   "source": [
    "## 2. Types of AI Agents\n",
    "\n",
    "Agents come in different flavors based on their decision-making complexity:\n",
    "\n",
    "### Reactive Agents\n",
    "- **How they work**: Directly map percepts to actions (stimulus ‚Üí response)\n",
    "- **Pros**: Fast, simple, predictable\n",
    "- **Cons**: No memory, can't handle complex scenarios\n",
    "- **Example**: Thermostat that turns heating on/off based on temperature\n",
    "\n",
    "### Deliberative Agents\n",
    "- **How they work**: Use reasoning with planning and world models\n",
    "- **Pros**: Handle complex goals, can plan ahead\n",
    "- **Cons**: Slower, computationally expensive\n",
    "- **Example**: Chess engine that thinks multiple moves ahead\n",
    "\n",
    "### Hybrid Agents\n",
    "- **How they work**: Combine reactive speed with deliberative reasoning\n",
    "- **Pros**: Fast responses + smart planning\n",
    "- **Cons**: More complex to implement\n",
    "- **Example**: Self-driving car (reacts to obstacles instantly, plans routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a86baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive: Agent Type Explorer\n",
    "# Try different agent types and see their characteristics\n",
    "\n",
    "from ipywidgets import interactive, RadioButtons, IntSlider, Output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "agent_types = {\n",
    "    \"Reactive\": {\n",
    "        \"description\": \"Direct stimulus-response\",\n",
    "        \"speed\": \"‚ö° Very Fast\",\n",
    "        \"memory\": \"None\",\n",
    "        \"planning\": \"None\",\n",
    "        \"example\": \"Ant colony behavior, simple robots\",\n",
    "        \"code_example\": \"if temperature > 25:\\n    turn_ac_on()\"\n",
    "    },\n",
    "    \"Deliberative\": {\n",
    "        \"description\": \"Planning-based decision making\",\n",
    "        \"speed\": \"üê¢ Slow\",\n",
    "        \"memory\": \"Full world model\",\n",
    "        \"planning\": \"Extensive\",\n",
    "        \"example\": \"Chess AI, route planning\",\n",
    "        \"code_example\": \"plan = search_for_goal(world_model)\\nexecute_plan(plan)\"\n",
    "    },\n",
    "    \"Hybrid\": {\n",
    "        \"description\": \"Reactive layer + deliberative layer\",\n",
    "        \"speed\": \"‚ö° Fast with planning\",\n",
    "        \"memory\": \"Selective memory\",\n",
    "        \"planning\": \"Strategic\",\n",
    "        \"example\": \"Self-driving cars, game AI\",\n",
    "        \"code_example\": \"react_to_immediate_threats()\\nplan_long_term_strategy()\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def show_agent_type(agent_type):\n",
    "    info = agent_types[agent_type]\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ü§ñ {agent_type.upper()} AGENT\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Description: {info['description']}\")\n",
    "    print(f\"Speed: {info['speed']}\")\n",
    "    print(f\"Memory: {info['memory']}\")\n",
    "    print(f\"Planning Capability: {info['planning']}\")\n",
    "    print(f\"Real-world Example: {info['example']}\")\n",
    "    print(f\"\\nCode Pattern:\")\n",
    "    print(f\"```python\")\n",
    "    print(info['code_example'])\n",
    "    print(f\"```\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Create interactive widget\n",
    "agent_selector = RadioButtons(\n",
    "    options=[\"Reactive\", \"Deliberative\", \"Hybrid\"],\n",
    "    value=\"Reactive\",\n",
    "    description='Choose Agent Type:'\n",
    ")\n",
    "\n",
    "interactive(show_agent_type, agent_type=agent_selector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282925e5",
   "metadata": {},
   "source": [
    "## 3. Agent Architecture and Components\n",
    "\n",
    "Every agent has core components that work together:\n",
    "\n",
    "### The Four Essential Components\n",
    "\n",
    "#### 1. **Sensors** (Perception Module)\n",
    "- Collect information from the environment\n",
    "- Convert real-world signals into data the agent understands\n",
    "- Examples: cameras, temperature sensors, user input, APIs\n",
    "\n",
    "#### 2. **Decision Engine** (Brain)\n",
    "- Processes sensor data using rules, ML models, or reasoning algorithms\n",
    "- Decides what action to take based on goals and constraints\n",
    "- Examples: neural networks, decision trees, logic systems\n",
    "\n",
    "#### 3. **Actuators** (Action Module)\n",
    "- Execute decisions in the physical or digital world\n",
    "- Convert agent decisions into environmental changes\n",
    "- Examples: motors, displays, API calls, network requests\n",
    "\n",
    "#### 4. **Memory** (Knowledge Base)\n",
    "- Stores past experiences and learned information\n",
    "- Enables agents to recognize patterns and improve over time\n",
    "- Examples: experience history, learned models, world state representation\n",
    "\n",
    "### How They Connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd4c954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive: Build and Visualize an Agent Architecture\n",
    "# Toggle components on/off to see how they interact\n",
    "\n",
    "from ipywidgets import Checkbox, HBox, VBox, Output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "class AgentComponent:\n",
    "    def __init__(self, name, description, icon):\n",
    "        self.name = name\n",
    "        self.description = description\n",
    "        self.icon = icon\n",
    "        self.enabled = True\n",
    "\n",
    "# Define components\n",
    "components = {\n",
    "    \"sensors\": AgentComponent(\"Sensors\", \"Perceives environment (cameras, data, APIs)\", \"üëÅÔ∏è\"),\n",
    "    \"memory\": AgentComponent(\"Memory\", \"Stores experiences and learned patterns\", \"üß†\"),\n",
    "    \"decision\": AgentComponent(\"Decision Engine\", \"Processes info and chooses actions\", \"‚öôÔ∏è\"),\n",
    "    \"actuators\": AgentComponent(\"Actuators\", \"Executes actions in the world\", \"üí™\")\n",
    "}\n",
    "\n",
    "output = Output()\n",
    "\n",
    "def visualize_architecture(show_sensors, show_memory, show_decision, show_actuators):\n",
    "    with output:\n",
    "        output.clear()\n",
    "        \n",
    "        enabled = {\n",
    "            \"sensors\": show_sensors,\n",
    "            \"memory\": show_memory,\n",
    "            \"decision\": show_decision,\n",
    "            \"actuators\": show_actuators\n",
    "        }\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üèóÔ∏è  AGENT ARCHITECTURE VISUALIZATION\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "        \n",
    "        # Visualization\n",
    "        active_components = []\n",
    "        \n",
    "        if enabled[\"sensors\"]:\n",
    "            active_components.append(\"üëÅÔ∏è  SENSORS ‚Üí Read environment\")\n",
    "        if enabled[\"memory\"]:\n",
    "            active_components.append(\"üß†  MEMORY ‚Üê Store experiences\")\n",
    "        if enabled[\"decision\"]:\n",
    "            active_components.append(\"‚öôÔ∏è  DECISION ENGINE ‚Üê Process & decide\")\n",
    "        if enabled[\"actuators\"]:\n",
    "            active_components.append(\"üí™  ACTUATORS ‚Üê Execute actions\")\n",
    "        \n",
    "        if not active_components:\n",
    "            print(\"‚ùå Select at least one component!\")\n",
    "        else:\n",
    "            for comp in active_components:\n",
    "                print(comp)\n",
    "            \n",
    "            print(\"\\n\" + \"-\"*60)\n",
    "            print(\"Flow: \", end=\"\")\n",
    "            \n",
    "            flow_parts = []\n",
    "            if enabled[\"sensors\"]:\n",
    "                flow_parts.append(\"Percept\")\n",
    "            if enabled[\"decision\"]:\n",
    "                flow_parts.append(\"Decide\")\n",
    "            if enabled[\"actuators\"]:\n",
    "                flow_parts.append(\"Act\")\n",
    "            if enabled[\"memory\"]:\n",
    "                flow_parts.append(\"Learn\")\n",
    "            \n",
    "            print(\" ‚Üí \".join(flow_parts))\n",
    "            print(\"-\"*60 + \"\\n\")\n",
    "            \n",
    "            # Show status\n",
    "            print(\"‚úÖ Agent is ACTIVE\" if all(enabled.values()) else \"‚ö†Ô∏è  Agent is INCOMPLETE\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Create checkboxes\n",
    "checkboxes = VBox([\n",
    "    Checkbox(value=True, description='Sensors'),\n",
    "    Checkbox(value=True, description='Memory'),\n",
    "    Checkbox(value=True, description='Decision Engine'),\n",
    "    Checkbox(value=True, description='Actuators'),\n",
    "])\n",
    "\n",
    "# Create interactive visualization\n",
    "interactive_plot = interactive(\n",
    "    visualize_architecture,\n",
    "    show_sensors=checkboxes.children[0],\n",
    "    show_memory=checkboxes.children[1],\n",
    "    show_decision=checkboxes.children[2],\n",
    "    show_actuators=checkboxes.children[3]\n",
    ")\n",
    "\n",
    "display(VBox([\n",
    "    widgets.HTML(\"<b>Toggle components to see architecture:</b>\"),\n",
    "    checkboxes,\n",
    "    output\n",
    "]))\n",
    "\n",
    "# Run initial visualization\n",
    "visualize_architecture(True, True, True, True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b39490",
   "metadata": {},
   "source": [
    "## 4. Building a Simple Reactive Agent\n",
    "\n",
    "Let's build our first agent! We'll create a **smart thermostat agent** that maintains room temperature.\n",
    "\n",
    "### The Agent's Task:\n",
    "- **Goal**: Keep room temperature between 20-25¬∞C\n",
    "- **Type**: Reactive agent (direct stimulus-response)\n",
    "- **Sensors**: Temperature sensor\n",
    "- **Actuators**: Heater and AC unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b72c450",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThermostatAgent:\n",
    "    \"\"\"\n",
    "    A simple reactive agent that controls room temperature.\n",
    "    \n",
    "    This agent:\n",
    "    1. Perceives the current temperature\n",
    "    2. Decides what to do based on rules\n",
    "    3. Acts by turning heating/cooling on or off\n",
    "    4. Learns nothing (reactive agent)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, target_min=20, target_max=25):\n",
    "        self.target_min = target_min\n",
    "        self.target_max = target_max\n",
    "        self.heating_on = False\n",
    "        self.cooling_on = False\n",
    "        self.action_history = []\n",
    "    \n",
    "    def perceive(self, current_temp):\n",
    "        \"\"\"Step 1: Sense the environment\"\"\"\n",
    "        return current_temp\n",
    "    \n",
    "    def decide(self, current_temp):\n",
    "        \"\"\"Step 2: Use rules to decide what to do\"\"\"\n",
    "        \n",
    "        if current_temp < self.target_min:\n",
    "            return \"HEAT\"\n",
    "        elif current_temp > self.target_max:\n",
    "            return \"COOL\"\n",
    "        else:\n",
    "            return \"IDLE\"\n",
    "    \n",
    "    def act(self, action):\n",
    "        \"\"\"Step 3: Execute the action\"\"\"\n",
    "        \n",
    "        if action == \"HEAT\":\n",
    "            self.heating_on = True\n",
    "            self.cooling_on = False\n",
    "            effect = \"üî• Heating turned ON\"\n",
    "        elif action == \"COOL\":\n",
    "            self.heating_on = False\n",
    "            self.cooling_on = True\n",
    "            effect = \"‚ùÑÔ∏è  Cooling turned ON\"\n",
    "        else:\n",
    "            self.heating_on = False\n",
    "            self.cooling_on = False\n",
    "            effect = \"‚úÖ Both systems OFF (comfortable!)\"\n",
    "        \n",
    "        self.action_history.append(action)\n",
    "        return effect\n",
    "    \n",
    "    def run(self, current_temp):\n",
    "        \"\"\"Execute one complete agent cycle: Perceive ‚Üí Decide ‚Üí Act\"\"\"\n",
    "        \n",
    "        percept = self.perceive(current_temp)\n",
    "        action = self.decide(percept)\n",
    "        effect = self.act(action)\n",
    "        \n",
    "        return {\n",
    "            \"temperature\": percept,\n",
    "            \"decision\": action,\n",
    "            \"effect\": effect\n",
    "        }\n",
    "\n",
    "# Create an agent instance\n",
    "thermostat = ThermostatAgent()\n",
    "\n",
    "print(\"üè† Smart Thermostat Agent Demo\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Target Temperature Range: 20-25¬∞C\\n\")\n",
    "\n",
    "# Test the agent with different temperatures\n",
    "test_temps = [18, 20, 22, 25, 28, 25, 22]\n",
    "\n",
    "for temp in test_temps:\n",
    "    result = thermostat.run(temp)\n",
    "    print(f\"Current Temp: {result['temperature']}¬∞C\")\n",
    "    print(f\"Decision: {result['decision']}\")\n",
    "    print(f\"Action: {result['effect']}\")\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total actions taken: {len(thermostat.action_history)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea61d15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive: Customize the Thermostat Agent!\n",
    "# Modify the temperature thresholds and see how the agent responds\n",
    "\n",
    "from ipywidgets import FloatSlider, Button, Output, VBox, HBox\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Create sliders for user input\n",
    "min_temp_slider = FloatSlider(\n",
    "    value=20,\n",
    "    min=15,\n",
    "    max=25,\n",
    "    step=0.5,\n",
    "    description='Min Temp (¬∞C):',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "max_temp_slider = FloatSlider(\n",
    "    value=25,\n",
    "    min=20,\n",
    "    max=30,\n",
    "    step=0.5,\n",
    "    description='Max Temp (¬∞C):',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "current_temp_slider = FloatSlider(\n",
    "    value=22,\n",
    "    min=15,\n",
    "    max=35,\n",
    "    step=0.5,\n",
    "    description='Current Temp (¬∞C):',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "output = Output()\n",
    "\n",
    "def test_thermostat(min_temp, max_temp, current_temp):\n",
    "    with output:\n",
    "        output.clear()\n",
    "        \n",
    "        # Validate inputs\n",
    "        if min_temp >= max_temp:\n",
    "            print(\"‚ùå Error: Min temperature must be less than Max!\")\n",
    "            return\n",
    "        \n",
    "        # Create agent with custom parameters\n",
    "        agent = ThermostatAgent(target_min=min_temp, target_max=max_temp)\n",
    "        \n",
    "        # Run the agent\n",
    "        result = agent.run(current_temp)\n",
    "        \n",
    "        # Display results\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ü§ñ AGENT RESPONSE\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"üìä Target Range: {min_temp}¬∞C - {max_temp}¬∞C\")\n",
    "        print(f\"üìà Current Temp: {current_temp}¬∞C\")\n",
    "        print(f\"\\nüß† Agent's Decision: {result['decision']}\")\n",
    "        print(f\"‚ö° Action Taken: {result['effect']}\")\n",
    "        \n",
    "        # Show reasoning\n",
    "        print(\"\\nüìù Agent Reasoning:\")\n",
    "        if current_temp < min_temp:\n",
    "            temp_diff = min_temp - current_temp\n",
    "            print(f\"   ‚Üí Too cold by {temp_diff:.1f}¬∞C ‚Üí Activate heating!\")\n",
    "        elif current_temp > max_temp:\n",
    "            temp_diff = current_temp - max_temp\n",
    "            print(f\"   ‚Üí Too hot by {temp_diff:.1f}¬∞C ‚Üí Activate cooling!\")\n",
    "        else:\n",
    "            print(f\"   ‚Üí Temperature is in comfort zone ‚Üí No action needed!\")\n",
    "        \n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Create interactive layout\n",
    "test_button = Button(description='Test Agent', button_style='info')\n",
    "\n",
    "def on_test_click(b):\n",
    "    test_thermostat(\n",
    "        min_temp_slider.value,\n",
    "        max_temp_slider.value,\n",
    "        current_temp_slider.value\n",
    "    )\n",
    "\n",
    "test_button.on_click(on_test_click)\n",
    "\n",
    "# Display controls\n",
    "display(VBox([\n",
    "    widgets.HTML(\"<b style='font-size: 14px;'>‚öôÔ∏è Configure Your Thermostat Agent</b>\"),\n",
    "    min_temp_slider,\n",
    "    max_temp_slider,\n",
    "    current_temp_slider,\n",
    "    test_button,\n",
    "    output\n",
    "]))\n",
    "\n",
    "# Run initial test\n",
    "test_thermostat(20, 25, 22)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb32825",
   "metadata": {},
   "source": [
    "## 5. Interactive Agent Simulation\n",
    "\n",
    "Now let's run a **full environmental simulation** where we can observe the agent operating over time. You can control the environment and watch the agent respond in real-time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db55ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ipywidgets import IntSlider, Dropdown, Button, Output, VBox, HBox\n",
    "import ipywidgets as widgets\n",
    "\n",
    "class EnvironmentSimulator:\n",
    "    \"\"\"Simulates an environment with temperature changes\"\"\"\n",
    "    \n",
    "    def __init__(self, initial_temp=22, external_pattern=\"stable\"):\n",
    "        self.initial_temp = initial_temp\n",
    "        self.current_temp = initial_temp\n",
    "        self.external_pattern = external_pattern\n",
    "        self.step = 0\n",
    "        self.temperatures = [initial_temp]\n",
    "        self.actions = []\n",
    "        self.agent = ThermostatAgent()\n",
    "    \n",
    "    def get_external_temp_change(self):\n",
    "        \"\"\"Simulate external temperature changes based on pattern\"\"\"\n",
    "        \n",
    "        if self.external_pattern == \"stable\":\n",
    "            return 0\n",
    "        elif self.external_pattern == \"warming\":\n",
    "            return 0.3  # Gradual warming\n",
    "        elif self.external_pattern == \"cooling\":\n",
    "            return -0.3  # Gradual cooling\n",
    "        elif self.external_pattern == \"chaotic\":\n",
    "            return np.sin(self.step * 0.5) * 2  # Sine wave pattern\n",
    "        elif self.external_pattern == \"morning\":\n",
    "            # Simulates waking up at 6am and heating/cooling throughout day\n",
    "            return 0.5 * np.sin((self.step - 6) * np.pi / 12)\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def step_simulation(self):\n",
    "        \"\"\"Run one step of the simulation\"\"\"\n",
    "        \n",
    "        # Apply external temperature change\n",
    "        external_change = self.get_external_temp_change()\n",
    "        self.current_temp += external_change\n",
    "        \n",
    "        # Apply agent actions\n",
    "        result = self.agent.run(self.current_temp)\n",
    "        \n",
    "        # Apply system effects (heating/cooling impacts)\n",
    "        if self.agent.heating_on:\n",
    "            self.current_temp += 0.8  # Heating warms up the room\n",
    "        elif self.agent.cooling_on:\n",
    "            self.current_temp -= 0.8  # Cooling cools down the room\n",
    "        \n",
    "        # Add some noise\n",
    "        self.current_temp += np.random.normal(0, 0.1)\n",
    "        \n",
    "        self.temperatures.append(self.current_temp)\n",
    "        self.actions.append(result['decision'])\n",
    "        self.step += 1\n",
    "    \n",
    "    def run_simulation(self, num_steps):\n",
    "        \"\"\"Run multiple steps and return data\"\"\"\n",
    "        \n",
    "        self.temperatures = [self.initial_temp]\n",
    "        self.actions = []\n",
    "        self.step = 0\n",
    "        \n",
    "        for _ in range(num_steps):\n",
    "            self.step_simulation()\n",
    "        \n",
    "        return self.temperatures, self.actions\n",
    "\n",
    "# Create simulation controls\n",
    "num_steps_slider = IntSlider(\n",
    "    value=50,\n",
    "    min=10,\n",
    "    max=200,\n",
    "    step=10,\n",
    "    description='Simulation Steps:',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "pattern_dropdown = Dropdown(\n",
    "    options=['stable', 'warming', 'cooling', 'chaotic', 'morning'],\n",
    "    value='stable',\n",
    "    description='Environment:'\n",
    ")\n",
    "\n",
    "simulation_output = Output()\n",
    "\n",
    "def run_simulation(num_steps, pattern):\n",
    "    with simulation_output:\n",
    "        simulation_output.clear()\n",
    "        \n",
    "        # Run the simulation\n",
    "        sim = EnvironmentSimulator(initial_temp=22, external_pattern=pattern)\n",
    "        temps, actions = sim.run_simulation(num_steps)\n",
    "        \n",
    "        # Create visualization\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "        \n",
    "        # Plot 1: Temperature over time\n",
    "        steps = range(len(temps))\n",
    "        ax1.plot(steps, temps, 'b-', linewidth=2, label='Room Temperature')\n",
    "        ax1.axhline(y=20, color='r', linestyle='--', label='Min Target (20¬∞C)')\n",
    "        ax1.axhline(y=25, color='g', linestyle='--', label='Max Target (25¬∞C)')\n",
    "        ax1.fill_between(steps, 20, 25, alpha=0.2, color='green', label='Comfort Zone')\n",
    "        ax1.set_xlabel('Time Step')\n",
    "        ax1.set_ylabel('Temperature (¬∞C)')\n",
    "        ax1.set_title(f'üè† Thermostat Agent Simulation - {pattern.capitalize()} Environment')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 2: Agent actions over time\n",
    "        action_map = {'HEAT': 1, 'IDLE': 0, 'COOL': -1}\n",
    "        action_values = [action_map[a] for a in actions]\n",
    "        colors = ['red' if a == 1 else 'green' if a == -1 else 'blue' for a in action_values]\n",
    "        \n",
    "        ax2.bar(range(len(actions)), action_values, color=colors, alpha=0.7)\n",
    "        ax2.set_xlabel('Time Step')\n",
    "        ax2.set_ylabel('Action')\n",
    "        ax2.set_title('Agent Actions Over Time')\n",
    "        ax2.set_yticks([-1, 0, 1])\n",
    "        ax2.set_yticklabels(['Cool ‚ùÑÔ∏è', 'Idle ‚úÖ', 'Heat üî•'])\n",
    "        ax2.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print statistics\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üìä SIMULATION RESULTS\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Environment: {pattern.capitalize()}\")\n",
    "        print(f\"Total Steps: {len(temps)-1}\")\n",
    "        print(f\"\\nTemperature Statistics:\")\n",
    "        print(f\"  Min: {min(temps):.2f}¬∞C\")\n",
    "        print(f\"  Max: {max(temps):.2f}¬∞C\")\n",
    "        print(f\"  Avg: {np.mean(temps):.2f}¬∞C\")\n",
    "        print(f\"  Std Dev: {np.std(temps):.2f}¬∞C\")\n",
    "        \n",
    "        heat_count = actions.count('HEAT')\n",
    "        cool_count = actions.count('COOL')\n",
    "        idle_count = actions.count('IDLE')\n",
    "        \n",
    "        print(f\"\\nAgent Actions:\")\n",
    "        print(f\"  üî• Heating: {heat_count} times ({heat_count/len(actions)*100:.1f}%)\")\n",
    "        print(f\"  ‚ùÑÔ∏è Cooling: {cool_count} times ({cool_count/len(actions)*100:.1f}%)\")\n",
    "        print(f\"  ‚úÖ Idle: {idle_count} times ({idle_count/len(actions)*100:.1f}%)\")\n",
    "        \n",
    "        # Calculate comfort\n",
    "        comfort_steps = sum(1 for t in temps if 20 <= t <= 25)\n",
    "        print(f\"\\nComfort Analysis:\")\n",
    "        print(f\"  Steps in comfort zone: {comfort_steps}/{len(temps)} ({comfort_steps/len(temps)*100:.1f}%)\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Create interactive layout\n",
    "run_button = Button(description='Run Simulation', button_style='success')\n",
    "\n",
    "def on_run_click(b):\n",
    "    run_simulation(num_steps_slider.value, pattern_dropdown.value)\n",
    "\n",
    "run_button.on_click(on_run_click)\n",
    "\n",
    "# Display controls\n",
    "display(VBox([\n",
    "    widgets.HTML(\"<b style='font-size: 14px;'>üî¨ Agent Simulation Control Panel</b>\"),\n",
    "    num_steps_slider,\n",
    "    pattern_dropdown,\n",
    "    run_button,\n",
    "    simulation_output\n",
    "]))\n",
    "\n",
    "# Run initial simulation\n",
    "run_simulation(50, 'stable')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7028ddc",
   "metadata": {},
   "source": [
    "## üéì Key Takeaways\n",
    "\n",
    "### What We Learned:\n",
    "\n",
    "1. **Agents are Autonomous Systems**\n",
    "   - They perceive, decide, and act without explicit human commands\n",
    "   - They operate in feedback loops, continuously adapting\n",
    "\n",
    "2. **Agent Types Vary in Complexity**\n",
    "   - Reactive: Fast, simple, no memory\n",
    "   - Deliberative: Smart planning, slower\n",
    "   - Hybrid: Best of both worlds\n",
    "\n",
    "3. **Components Work Together**\n",
    "   - Sensors gather data\n",
    "   - Decision engine processes it\n",
    "   - Actuators execute actions\n",
    "   - Memory enables learning\n",
    "\n",
    "4. **Agents Can Be Simple Yet Powerful**\n",
    "   - Even our basic thermostat agent makes intelligent decisions\n",
    "   - The power scales with more complex decision logic\n",
    "\n",
    "5. **Testing Reveals Agent Behavior**\n",
    "   - Simulations help us understand how agents adapt\n",
    "   - Different environments require different agent strategies\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- ‚úÖ Understand what agents are\n",
    "- üéØ Next: Build a deliberative agent that plans ahead\n",
    "- üß† Then: Add learning to make agents improve over time\n",
    "- ü§ù Finally: Create multi-agent systems\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Challenge Exercise\n",
    "\n",
    "**Modify the thermostat agent** to handle a new scenario:\n",
    "- Add a **\"weekend mode\"** where the target temperature range is different\n",
    "- Implement a **\"sleep mode\"** that's triggered at night\n",
    "- Make the agent **\"learn\"** from past experiences to improve comfort\n",
    "\n",
    "Try implementing one of these extensions in the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2240215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ Your Challenge: Extend the Thermostat Agent!\n",
    "# Uncomment one of the challenges below and implement it\n",
    "\n",
    "# CHALLENGE 1: Weekend Mode\n",
    "# ========================\n",
    "# Modify the ThermostatAgent class to support different temperature ranges\n",
    "# for weekdays vs weekends. The target range should change automatically.\n",
    "\n",
    "# def __init__(self, target_min_weekday=20, target_max_weekday=25,\n",
    "#              target_min_weekend=19, target_max_weekend=26):\n",
    "#     # Your code here\n",
    "#     pass\n",
    "\n",
    "# def is_weekend(self, hour):\n",
    "#     # Your code here: return True if it's weekend, False if weekday\n",
    "#     pass\n",
    "\n",
    "\n",
    "# CHALLENGE 2: Sleep Mode\n",
    "# =======================\n",
    "# Add a \"sleep mode\" that adjusts the target temperature range based on time\n",
    "# Sleep mode (10 PM - 6 AM): Target 18-22¬∞C (cooler for better sleep)\n",
    "# Awake mode: Target 20-25¬∞C (normal comfort zone)\n",
    "\n",
    "# def set_sleep_mode(self, is_sleeping):\n",
    "#     # Your code here\n",
    "#     pass\n",
    "\n",
    "\n",
    "# CHALLENGE 3: Learning from Experience\n",
    "# ======================================\n",
    "# Add memory to the agent so it learns which actions worked best\n",
    "# Track success: times when the agent achieved comfort zone with minimal action\n",
    "\n",
    "# def remember_outcome(self, action, result_temp):\n",
    "#     # Store this experience\n",
    "#     pass\n",
    "\n",
    "# def learn_optimal_action(self, current_temp):\n",
    "#     # Use past experience to make better decisions\n",
    "#     pass\n",
    "\n",
    "\n",
    "print(\"üéØ Ready to extend the agent?\")\n",
    "print(\"Choose a challenge above and implement your solution!\")\n",
    "print(\"\\nüìö Hints:\")\n",
    "print(\"- Challenge 1: Use day of week to switch between configurations\")\n",
    "print(\"- Challenge 2: Add a mode parameter that affects decision logic\")\n",
    "print(\"- Challenge 3: Keep a history of (temperature, action, outcome) tuples\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
